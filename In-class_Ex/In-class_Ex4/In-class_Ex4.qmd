---
title: "In-class Exercise4: Preparing Spatial Interaction Modelling Variables"
data: "9 December 2023"
date-modified: "last-modified"
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

## Getting started

```{r}
pacman::p_load(tidyverse, sf, httr, tmap, performance, ggpubr)
```

## Geocoding using SLA API

```{r}
url<-"https://www.onemap.gov.sg/api/common/elastic/search"

csv<-read_csv("data/aspatial/Generalinformationofschools.csv")
postcodes<-csv$`postal_code`

found<-data.frame()
not_found<-data.frame()

for(postcode in postcodes){
  query<-list('searchVal'=postcode,'returnGeom'='Y','getAddrDetails'='Y','pageNum'='1')
  res<- GET(url,query=query)
  
  if((content(res)$found)!=0){
    found<-rbind(found,data.frame(content(res))[4:13])
  } else{
    not_found = data.frame(postcode)
  }
}
```

```{r}
#| eval: false
merged = merge(csv, found, by.x = 'postal_code', by.y = 'results.POSTAL', all = TRUE)
write.csv(merged, file = "data/aspatial/schools.csv")
write.csv(not_found, file = "data/aspatial/not_found.csv")
```

## Converting an aspatial data into a simple feature tibble data.frame

### Importing and tidying school data

```{r}
School <- read_csv("data/aspatial/schools.csv") %>%
  rename(latitude = "results.LATITUDE",
         longitude = "results.LONGITUDE") %>%
  dplyr::select(postal_code, school_name, latitude, longitude)
```

### Converting as aspatial data into sf tibble data .frame

```{r}
School_sf <- st_as_sf(School,
                      coords = c("longitude", "latitude"),
                      crs=4326) %>%
  st_transform(crs = 3414)
```

### Plotting a point simple feature layer

```{r}
tmap_mode("view")
tm_shape(School_sf) +
  tm_dots() +
tm_view(set.zoom.limits = c(11, 14))
tmap_mode("plot")
```

```{r}
mpsz <- st_read(dsn = "data/geospatial/",
                layer = "MPSZ-2019") %>%
  st_transform(crs = 3414)
```

```{r}
tmap_options(check.and.fix = TRUE)
tm_shape(mpsz) +
  tm_polygons() +
tm_shape(School_sf) +
  tm_dots()
```

## **Performing point-in-polygon count process**

```{r}
mpsz$'SCHOOL_COUNT' <- lengths(
  st_intersects(
    mpsz, School_sf))
```

```{r}
summary(mpsz$SCHOOL_COUNT)
```

## **Data Integration and Final Touch-up**

```{r}
business_sf <- st_read(dsn = "data/geospatial",
                      layer = "Business")
```

```{r}
tmap_options(check.and.fix = TRUE)
tm_shape(mpsz) +
  tm_polygons() +
tm_shape(business_sf) +
  tm_dots()
```

```{r}
mpsz$`BUSINESS_COUNT`<- lengths(
  st_intersects(
    mpsz, business_sf))
```

```{r}
summary(mpsz$BUSINESS_COUNT)
```

```{r}
flow_data <- read_rds("data/rds/flow_data_tidy.rds") %>%
  dplyr::select(-c(SCHOOL_COUNT,BUSINESS_COUNT))
flow_data
```

```{r}
mpsz_tidy <- mpsz %>%
  st_drop_geometry() %>%
  dplyr::select(SUBZONE_C, SCHOOL_COUNT, BUSINESS_COUNT)
```

```{r}
flow_data <- flow_data %>%
  left_join(mpsz_tidy,
            by = c("DESTIN_SZ" = "SUBZONE_C")) #%>%
  # rename(TRIPS = MORNING_PEAK,
  #        DIST = dist)
```

### **Checking for variables with zero values**

```{r}
summary(flow_data)
```

```{r}
flow_data$SCHOOL_COUNT <- ifelse(
  flow_data$SCHOOL_COUNT == 0,
  0.99, flow_data$SCHOOL_COUNT)
flow_data$BUSINESS_COUNT <- ifelse(
  flow_data$BUSINESS_COUNT == 0,
  0.99, flow_data$BUSINESS_COUNT)
```

```{r}
summary(flow_data)
```

```{r}
write_rds(flow_data,
          "data/rds/flow_data_tidy.rds")
```
